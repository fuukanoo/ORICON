import pandas as pd
import os
import glob
from collections import defaultdict, Counter
import numpy as np

def analyze_question_compatibility():
    """
    è³ªå•é …ç›®ã®é•ã„ãŒåˆ†æã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è©³ç´°ã«åˆ†æ
    """
    print('=== è³ªå•é …ç›®äº’æ›æ€§ã®è©³ç´°åˆ†æ ===\n')
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š
    video_streaming_path = '/home/mohki7/projects/ORICON/data/å®šé¡åˆ¶å‹•ç”»é…ä¿¡.xlsx'
    other_data_path = '/home/mohki7/projects/ORICON/data/other_data'
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    all_industries_questions = load_all_industry_data(video_streaming_path, other_data_path)
    
    if not all_industries_questions:
        return
    
    # Step 1: è³ªå•ã‚«ãƒ†ã‚´ãƒªã®åˆ†é¡
    print('ã€Step 1ã€‘è³ªå•é …ç›®ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡')
    categorized_questions = categorize_questions(all_industries_questions)
    
    # Step 2: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ¥­ç¨®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
    print('\nã€Step 2ã€‘ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¥­ç¨®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ')
    coverage_analysis = analyze_category_coverage(categorized_questions, all_industries_questions)
    
    # Step 3: åˆ†æå¯èƒ½æ€§ã®è©•ä¾¡
    print('\nã€Step 3ã€‘å…·ä½“çš„åˆ†æå¯èƒ½æ€§ã®è©•ä¾¡')
    analysis_potential = evaluate_analysis_potential(coverage_analysis, all_industries_questions)
    
    # Step 4: æ¨å¥¨æˆ¦ç•¥ã®ææ¡ˆ
    print('\nã€Step 4ã€‘ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨æˆ¦ç•¥')
    recommend_strategies(analysis_potential, coverage_analysis)
    
    return analysis_potential

def load_all_industry_data(video_path, other_path):
    """å…¨æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    all_questions = {}
    
    # å‹•ç”»é…ä¿¡ãƒ‡ãƒ¼ã‚¿
    try:
        format_df = pd.read_excel(video_path, sheet_name='Format')
        valid_questions = format_df[format_df['Question'].notna() & format_df['Title'].notna()]
        video_questions = {}
        for _, row in valid_questions.iterrows():
            if pd.notna(row['Question']) and pd.notna(row['Title']):
                video_questions[row['Question']] = row['Title']
        all_questions['å®šé¡åˆ¶å‹•ç”»é…ä¿¡'] = video_questions
    except Exception as e:
        print(f"å‹•ç”»é…ä¿¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    # ä»–æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿
    for industry_dir in os.listdir(other_path):
        industry_path = os.path.join(other_path, industry_dir)
        if os.path.isdir(industry_path):
            excel_files = glob.glob(os.path.join(industry_path, '*.xlsx'))
            for excel_file in excel_files:
                try:
                    format_df = pd.read_excel(excel_file, sheet_name='Format')
                    valid_questions = format_df[format_df['Question'].notna() & format_df['Title'].notna()]
                    industry_questions = {}
                    for _, row in valid_questions.iterrows():
                        if pd.notna(row['Question']) and pd.notna(row['Title']):
                            industry_questions[row['Question']] = row['Title']
                    all_questions[industry_dir] = industry_questions
                except Exception as e:
                    print(f"{industry_dir} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return all_questions

def categorize_questions(all_questions):
    """è³ªå•é …ç›®ã‚’ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
    categories = {
        'basic_demographics': {
            'keywords': ['æ€§åˆ¥', 'å¹´é½¢', 'å±…ä½åœ°', 'åœ°åŸŸ', 'gender', 'age', 'location'],
            'questions': defaultdict(list)
        },
        'financial_info': {
            'keywords': ['å¹´å', 'ä¸–å¸¯', 'åå…¥', 'income', 'salary'],
            'questions': defaultdict(list)
        },
        'satisfaction': {
            'keywords': ['æº€è¶³', 'satisfaction', 'è©•ä¾¡', 'rating'],
            'questions': defaultdict(list)
        },
        'loyalty': {
            'keywords': ['ç¶šã‘', 'ç¶™ç¶š', 'continue', 'åˆ©ç”¨ã—ç¶šã‘'],
            'questions': defaultdict(list)
        },
        'recommendation': {
            'keywords': ['ã™ã™ã‚', 'recommend', 'æ¨å¥¨', 'ç´¹ä»‹'],
            'questions': defaultdict(list)
        },
        'usage_behavior': {
            'keywords': ['åˆ©ç”¨', 'use', 'ä½¿ç”¨', 'é »åº¦', 'frequency'],
            'questions': defaultdict(list)
        },
        'content_preference': {
            'keywords': ['ã‚¸ãƒ£ãƒ³ãƒ«', 'genre', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'content', 'ç•ªçµ„'],
            'questions': defaultdict(list)
        }
    }
    
    for industry, questions in all_questions.items():
        for q_id, q_title in questions.items():
            q_title_lower = q_title.lower()
            
            for category, info in categories.items():
                for keyword in info['keywords']:
                    if keyword in q_title or keyword in q_title_lower:
                        categories[category]['questions'][industry].append((q_id, q_title))
                        break
    
    # åˆ†é¡çµæœã®è¡¨ç¤º
    for category, info in categories.items():
        total_questions = sum(len(qs) for qs in info['questions'].values())
        coverage = len(info['questions'])
        print(f'{category}: {total_questions}è³ªå•, {coverage}/14æ¥­ç¨®ã§ã‚«ãƒãƒ¼')
    
    return categories

def analyze_category_coverage(categorized_questions, all_questions):
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ¥­ç¨®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’åˆ†æ"""
    total_industries = len(all_questions)
    
    coverage_summary = {}
    
    for category, info in categorized_questions.items():
        industries_with_category = set(info['questions'].keys())
        coverage_ratio = len(industries_with_category) / total_industries
        
        # å„æ¥­ç¨®ã§ã®è³ªå•æ•°
        question_counts = {industry: len(questions) 
                          for industry, questions in info['questions'].items()}
        
        avg_questions = np.mean(list(question_counts.values())) if question_counts else 0
        
        coverage_summary[category] = {
            'coverage_ratio': coverage_ratio,
            'covered_industries': len(industries_with_category),
            'avg_questions_per_industry': avg_questions,
            'industries_list': list(industries_with_category),
            'question_counts': question_counts
        }
        
        print(f'\n=== {category} ===')
        print(f'æ¥­ç¨®ã‚«ãƒãƒ¬ãƒƒã‚¸: {len(industries_with_category)}/{total_industries} ({coverage_ratio:.1%})')
        print(f'å¹³å‡è³ªå•æ•°/æ¥­ç¨®: {avg_questions:.1f}')
        
        if len(industries_with_category) > 0:
            print('ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¥­ç¨®:')
            for industry in sorted(industries_with_category):
                count = question_counts[industry]
                print(f'  {industry}: {count}è³ªå•')
    
    return coverage_summary

def evaluate_analysis_potential(coverage_summary, all_questions):
    """å…·ä½“çš„ãªåˆ†æå¯èƒ½æ€§ã‚’è©•ä¾¡"""
    
    # å„åˆ†æã‚¿ã‚¤ãƒ—ã«å¿…è¦ãªæœ€ä½ã‚«ãƒ†ã‚´ãƒª
    analysis_types = {
        'customer_segmentation': {
            'required_categories': ['basic_demographics', 'financial_info'],
            'min_coverage': 0.8,  # 80%ä»¥ä¸Šã®æ¥­ç¨®ã§ã‚«ãƒãƒ¼
            'description': 'é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ'
        },
        'satisfaction_correlation': {
            'required_categories': ['basic_demographics', 'satisfaction'],
            'min_coverage': 0.7,
            'description': 'æº€è¶³åº¦ç›¸é–¢åˆ†æ'
        },
        'loyalty_prediction': {
            'required_categories': ['satisfaction', 'loyalty', 'usage_behavior'],
            'min_coverage': 0.6,
            'description': 'ãƒ­ã‚¤ãƒ¤ãƒ«ãƒ†ã‚£äºˆæ¸¬åˆ†æ'
        },
        'nps_analysis': {
            'required_categories': ['recommendation', 'satisfaction'],
            'min_coverage': 0.7,
            'description': 'NPSåˆ†æ'
        },
        'content_preference_analysis': {
            'required_categories': ['basic_demographics', 'content_preference'],
            'min_coverage': 0.5,
            'description': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é¸å¥½åˆ†æ'
        }
    }
    
    analysis_feasibility = {}
    
    for analysis_type, requirements in analysis_types.items():
        # å¿…è¦ã‚«ãƒ†ã‚´ãƒªã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ãƒã‚§ãƒƒã‚¯
        category_coverages = []
        missing_categories = []
        
        for required_cat in requirements['required_categories']:
            if required_cat in coverage_summary:
                coverage = coverage_summary[required_cat]['coverage_ratio']
                category_coverages.append(coverage)
                if coverage < requirements['min_coverage']:
                    missing_categories.append(required_cat)
            else:
                category_coverages.append(0)
                missing_categories.append(required_cat)
        
        # ç·åˆå®Ÿè¡Œå¯èƒ½æ€§ã‚¹ã‚³ã‚¢
        min_coverage = min(category_coverages) if category_coverages else 0
        avg_coverage = np.mean(category_coverages) if category_coverages else 0
        
        is_feasible = (min_coverage >= requirements['min_coverage'] and 
                      len(missing_categories) == 0)
        
        analysis_feasibility[analysis_type] = {
            'feasible': is_feasible,
            'min_coverage': min_coverage,
            'avg_coverage': avg_coverage,
            'missing_categories': missing_categories,
            'description': requirements['description']
        }
        
        # çµæœè¡¨ç¤º
        status = "âœ… å®Ÿè¡Œå¯èƒ½" if is_feasible else "âŒ åˆ¶ç´„ã‚ã‚Š"
        print(f'\n{requirements["description"]}: {status}')
        print(f'  æœ€ä½ã‚«ãƒãƒ¬ãƒƒã‚¸: {min_coverage:.1%} (è¦æ±‚: {requirements["min_coverage"]:.1%})')
        print(f'  å¹³å‡ã‚«ãƒãƒ¬ãƒƒã‚¸: {avg_coverage:.1%}')
        
        if missing_categories:
            print(f'  ä¸è¶³ã‚«ãƒ†ã‚´ãƒª: {", ".join(missing_categories)}')
        
        if is_feasible:
            # å®Ÿè¡Œå¯èƒ½ãªæ¥­ç¨®ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
            common_industries = set(all_questions.keys())
            for required_cat in requirements['required_categories']:
                if required_cat in coverage_summary:
                    common_industries = common_industries.intersection(
                        set(coverage_summary[required_cat]['industries_list'])
                    )
            print(f'  å¯¾è±¡æ¥­ç¨®æ•°: {len(common_industries)}')
            if len(common_industries) <= 5:
                print(f'  å¯¾è±¡æ¥­ç¨®: {", ".join(sorted(common_industries))}')
    
    return analysis_feasibility

def recommend_strategies(analysis_potential, coverage_summary):
    """ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨æˆ¦ç•¥ã‚’ææ¡ˆ"""
    
    # å®Ÿè¡Œå¯èƒ½ãªåˆ†æã®ç‰¹å®š
    feasible_analyses = [analysis for analysis, info in analysis_potential.items() 
                        if info['feasible']]
    
    print(f'\n=== æ¨å¥¨åˆ†ææˆ¦ç•¥ ===')
    print(f'å®Ÿè¡Œå¯èƒ½ãªåˆ†æ: {len(feasible_analyses)}/5')
    
    if len(feasible_analyses) >= 3:
        print('ğŸ¯ ã€æ¨å¥¨ã€‘åŒ…æ‹¬çš„åˆ†æã‚¢ãƒ—ãƒ­ãƒ¼ãƒ')
        print('   è¤‡æ•°ã®åˆ†ææ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ãŸç·åˆçš„ãªè©•ä¾¡ãŒå¯èƒ½')
        
        for analysis in feasible_analyses:
            print(f'   âœ“ {analysis_potential[analysis]["description"]}')
    
    elif len(feasible_analyses) >= 1:
        print('âš ï¸ ã€æ¨å¥¨ã€‘é™å®šçš„åˆ†æã‚¢ãƒ—ãƒ­ãƒ¼ãƒ')
        print('   åˆ©ç”¨å¯èƒ½ãªåˆ†ææ‰‹æ³•ã«é™å®šã—ã¦å®Ÿè¡Œ')
        
        for analysis in feasible_analyses:
            print(f'   âœ“ {analysis_potential[analysis]["description"]}')
    
    else:
        print('ğŸš¨ ã€è­¦å‘Šã€‘åˆ†æå®Ÿè¡Œå›°é›£')
        print('   ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯ååˆ†ãªåˆ†æãŒå›°é›£')
    
    # ãƒ‡ãƒ¼ã‚¿æ”¹å–„ææ¡ˆ
    print(f'\n=== ãƒ‡ãƒ¼ã‚¿æ”¹å–„ææ¡ˆ ===')
    
    # æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
    category_priorities = sorted(coverage_summary.items(), 
                               key=lambda x: x[1]['coverage_ratio'])
    
    print('å„ªå…ˆæ”¹å–„ã‚«ãƒ†ã‚´ãƒª:')
    for category, info in category_priorities[:3]:
        improvement_potential = len(info['industries_list'])
        print(f'  {category}: ç¾åœ¨{improvement_potential}/14æ¥­ç¨® â†’ ç›®æ¨™12+æ¥­ç¨®')
        print(f'    æ”¹å–„ã«ã‚ˆã‚Šå®Ÿè¡Œå¯èƒ½ã«ãªã‚‹åˆ†æãŒå¢—åŠ ')
    
    # æœ€é©ãªåˆ†æå¯¾è±¡æ¥­ç¨®ã®ææ¡ˆ
    print(f'\n=== æœ€é©åˆ†æå¯¾è±¡æ¥­ç¨® ===')
    
    # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã§é«˜ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŒã¤æ¥­ç¨®ã‚’ç‰¹å®š
    industry_scores = defaultdict(int)
    
    for category, info in coverage_summary.items():
        weight = info['coverage_ratio'] * info['avg_questions_per_industry']
        for industry in info['industries_list']:
            industry_scores[industry] += weight
    
    top_industries = sorted(industry_scores.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print('ãƒ‡ãƒ¼ã‚¿è±Šå¯Œåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:')
    for i, (industry, score) in enumerate(top_industries, 1):
        print(f'  {i}. {industry}: ã‚¹ã‚³ã‚¢ {score:.2f}')

if __name__ == "__main__":
    analyze_question_compatibility() 